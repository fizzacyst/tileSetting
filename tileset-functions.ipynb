{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0369646",
   "metadata": {},
   "source": [
    "# TileSetter v2.0\n",
    "\n",
    "Made by Cady\n",
    "\n",
    "Prefixes + Suffixes adapted from Denam\n",
    "\n",
    "Last updated 9/5/2021\n",
    "\n",
    "## Running This Code\n",
    "**Press Shift + Enter to run each individual code block.**\n",
    "The first several blocks are loading data + defining functions. The actual name constructor is several blocks down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f7054ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Import block\n",
    "\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import datetime as dt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa5320b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Initialize, update file paths if needed\n",
    "\n",
    "# ----> Check for Updates\n",
    "update_prefixes = False\n",
    "update_suffixes = False\n",
    "\n",
    "# ----> Current filepaths\n",
    "f_sticky  = './data/stuck-strings/stuck-strings-2021-09-03.csv'\n",
    "f_prefix  = './data/word_segments/from-denam/prefixes.csv'\n",
    "f_suffix  = './data/word_segments/my-segments/suffixes.csv'\n",
    "f_webpage = './HTML/webpage.html'\n",
    "f_css     = 'style.css'\n",
    "\n",
    "# ----> Load alphabet with and without underscores\n",
    "abcs = pd.DataFrame(list(string.ascii_lowercase),columns=['Letter'])\n",
    "abcs_ = abcs.append({'Letter':'~'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b65cf48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading Functions Block\n",
    "\n",
    "\n",
    "#-! Importing Current Prefixes ---------------------------------#\n",
    "def updateStuckPrefixes(prefix_path,stucks_path,alphabet=abcs_):\n",
    "    \n",
    "    print('Prefixes from file:   ' + prefix_path)\n",
    "    print('Stickies from file:   ' + stucks_path)\n",
    "    \n",
    "    # ----> Load prefixes <----\n",
    "    pre = pd.read_csv(prefix_path,names=['prefix'])\n",
    "    pre.prefix = pre.prefix.str.lower()\n",
    "    pre['L'] = pre.prefix.str.len()\n",
    "    \n",
    "    print('4L+ prefixes:         ' + str(len(pre)))\n",
    "    \n",
    "    # ----> Load current stuck 3L strings <----\n",
    "    stuck_strings = pd.read_csv(stucks_path)\n",
    "    stuck_strings.prefix = stuck_strings.prefix.str.lower()\n",
    "    stuck_strings.marker = stuck_strings.marker.str.lower()\n",
    "\n",
    "    pr3,markers = loadStuck3Ls(stuck_strings) \n",
    "    print('3L prefixes:          ' + str(len(pr3)))\n",
    "\n",
    "    # ----> Combine 3L and 4L+ prefixes <----\n",
    "    pre = pd.concat([pre, pr3],ignore_index=True)\n",
    "    pre = pre.sort_values(by=['prefix','L']).reset_index(drop=True)\n",
    "    pre = pre.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "     \n",
    "    # ----> Drop inactive prefixes <----\n",
    "    N1 = len(pre[~pre.prefix.str.slice(stop=3).isin(pre.prefix[pre.L==3])])\n",
    "    pre = pre[pre.prefix.str.slice(stop=3).isin(pre.prefix[pre.L==3])]\n",
    "    pre, N2 = applyMarkers(pre,'prefix',markers)\n",
    "        \n",
    "    print('Outdated Prefixes:    ' + str(N1+N2))  \n",
    "    print('Total Prefixes:       '+  str(len(pre)))\n",
    "    \n",
    "    # ----> Write CSV <----\n",
    "    pre.replace('\\~','_',regex=True)\\\n",
    "        .to_csv('./word_segments/my-segments/prefixes_current.csv', index=False)\n",
    "    \n",
    "    \n",
    "    pre.replace('\\_','~', regex=True)\n",
    "    return pre,markers\n",
    "\n",
    "#-! Load all 3L prefixes + markers names -----------------------------#\n",
    "def loadStuck3Ls(stucks, abcs=abcs_):\n",
    "    \n",
    "    stucks = stucks.replace('\\_','~',regex=True)\n",
    "    new_pres = pd.DataFrame(columns=['prefix','L'])\n",
    "    \n",
    "    \n",
    "    for i in stucks.prefix:\n",
    "        dat = pd.DataFrame(columns=['pr','e'])\n",
    "\n",
    "        L3 = i[2].lower()\n",
    "        L3_i = abcs[abcs.Letter == L3].index.tolist()[0]\n",
    "\n",
    "        dat['e']  = abcs[abcs.index >= L3_i].reset_index(drop=True).squeeze()\n",
    "        dat['pr'] = dat.assign(pr = i[0:2])\n",
    "\n",
    "        dat['prefix'] = dat.pr + dat.e\n",
    "        dat['L'] = 3\n",
    "\n",
    "        new_pres = pd.concat([new_pres,dat],ignore_index=True)\n",
    "\n",
    "    new_pres.prefix = new_pres.prefix.str.lower()\n",
    "    new_pres = new_pres.drop(['pr','e'],axis=1).sort_values(by='prefix').reset_index(drop=True)\n",
    "    \n",
    "    return new_pres,stucks\n",
    "\n",
    "#-! Load Active Marker Names ---------------------------------#\n",
    "def loadActiveMarkers(stucks_path):\n",
    "    markers = pd.read_csv(stucks_path)\n",
    "    markers = markers.replace('\\_','~',regex=True)\n",
    "    markers.prefix = markers.prefix.str.lower()\n",
    "    markers.marker = markers.marker.str.lower()\n",
    "    return markers\n",
    "\n",
    "#-! Apply Active Marker Names ---------------------------------#\n",
    "def applyMarkers(namebits,bit_label,markers,abcs_=abcs_):\n",
    "    # ----> Prepare input name strings <----\n",
    "    strs = pd.DataFrame( {\n",
    "        'bits': namebits[bit_label].copy(), \n",
    "        'L':    namebits.L.copy()           \n",
    "    })\n",
    "\n",
    "    # ----> Prepare 3L sticky strings ('starts') <----\n",
    "    marky_bits = pd.DataFrame( {\n",
    "        'bits': markers.prefix.copy(),   \n",
    "        'L':    1000\n",
    "    })\n",
    "    marky_bits.index = 'p' + marky_bits.index.astype(str)\n",
    "    \n",
    "    # ----> Prepare marker names ('stops') <----\n",
    "    marky_marks = pd.DataFrame({\n",
    "        'bits': markers.marker.copy(),\n",
    "        'L':    1000\n",
    "    })  \n",
    "    marky_marks.index = 'm' + marky_marks.index.astype(str)\n",
    "    \n",
    "    # ----> Smoosh the things together <----\n",
    "    yar = pd.concat([marky_bits,strs,marky_marks])\\\n",
    "            .sort_values(by=['bits','L'])\n",
    "    \n",
    "    # ----> Reindex and rename <----\n",
    "    yar = yar.reset_index()\n",
    "    yar = yar.rename(columns={'index':'flag'})\n",
    "    yar.flag = yar.flag.astype(str)\n",
    "    yar['L'] = yar.bits.str.len()\n",
    "    \n",
    "    # ----> Find the start and stop points <----\n",
    "    starts = yar[yar.flag.str.contains('p')]\\\n",
    "                .index.tolist()\n",
    "    stops  = yar[yar.flag.str.contains('m')]\\\n",
    "                .index.tolist()\n",
    "    \n",
    "    lims = pd.DataFrame({'start': starts, \\\n",
    "                         'stop':  stops})\n",
    "\n",
    "    # ---> Make List of indicies to drop < ----\n",
    "    for i in lims.index:     \n",
    "        yeet = np.arange( lims.start[i], lims.stop[i])\n",
    "        \n",
    "        if i == 0:\n",
    "            yardrop = yeet\n",
    "        else:\n",
    "            yardrop = np.insert(yardrop,len(yardrop),yeet)\n",
    "\n",
    "    yar = yar.copy().drop(yardrop,axis=0) # Drop names\n",
    "    \n",
    "    if bit_label == 'Neopet':\n",
    "        yar[~yar['flag']=='p0'] # Drop marker from already-generated names\n",
    "    \n",
    "    yar = yar.drop('flag',1).reset_index(drop=True) # Drop flag column\n",
    "    yar = yar.rename(columns={'bits': bit_label})\n",
    "    \n",
    "    return yar, len(yardrop)\n",
    "\n",
    "\n",
    "\n",
    "#-! Importing Denam's Suffixes ----------------------------------------------##\n",
    "def LoadDenamSuffixes():\n",
    "    suffix = pd.read_csv('./data/word_segments/from-denam/3L.csv',names=['suffix'])\n",
    "    suffix['L'] = 3\n",
    "\n",
    "    suf = ['abc','def','ghi','jkl','mno','pqr','stu','vwxyz']\n",
    "    for i in suf:\n",
    "        dat = pd.read_csv('./word_segments/4L_'+i+'.csv',names=['suffix'])\n",
    "        dat['L'] = dat.suffix.str.len()\n",
    "\n",
    "        suffix = suffix.append(dat, ignore_index=True)\n",
    "    \n",
    "    return suffix\n",
    "\n",
    "\n",
    "# -----> Load Prefixes\n",
    "if update_prefixes == True:\n",
    "    pres_,marks = updateStuckPrefixes(f_prefix,f_sticky)\n",
    "else:\n",
    "    pres_ = pd.read_csv('./data/word_segments/my-segments/prefixes_current.csv')\n",
    "    pres_ = pres_.replace('\\_','~', regex=True)\n",
    "    marks = loadActiveMarkers(f_sticky)\n",
    "    \n",
    "pres = pres_.copy()[~pres_.prefix.str.contains('~')].reset_index(drop=True)\n",
    "\n",
    "# -----> Load suffixes    \n",
    "if update_suffixes == True:\n",
    "    print('No current function available to update suffixes from new file.')\n",
    "    print('Please create one.')\n",
    "else:\n",
    "    sufs = pd.read_csv(f_suffix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eda5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Functions to make Pages ########\n",
    "\n",
    "#-! Make Webpage --------------------#\n",
    "def make_page(names,linky='petpage'):\n",
    "    \n",
    "    names['Neopet'] = names.Neopet.str.replace('~','_')\n",
    "\n",
    "    css_tag = '<link rel=\"stylesheet\" type=\"text/css\" '+ \\\n",
    "              'href=\"' + f_css + '\">'\n",
    "\n",
    "    # ---> generate img + link urls\n",
    "    names = get_links(names)\n",
    "    \n",
    "    # ---> Page build starts here\n",
    "    page = [css_tag]\n",
    "    \n",
    "    # ---> + 1 'letter' div for each name length\n",
    "    for i in names.L.unique():\n",
    "        iLs = str(i) + ' Letters'\n",
    "        page += ['<div class=\"letter\">']\n",
    "        page += ['<h2>'+str(iLs)+'</h2>']\n",
    "        \n",
    "        nameLs = names[names.L == i]\n",
    "        \n",
    "        # ---> Generate image+link code for 'pet' divs\n",
    "        linkme = nameLs.Neopet + '<br>' + img_wrap(nameLs.img)\n",
    "        divp = div_wrap(a_wrap(linkme,nameLs[linky]))\n",
    "        \n",
    "        page += divp.values.tolist() + ['</div><br>']\n",
    "\n",
    "    # ---> Save webpage code using Panda's .to_csv\n",
    "    webpage = pd.Series(page)  \n",
    "    webpage.to_csv(f_webpage,\n",
    "                    sep=',',header=False,index=False,quoting=csv.QUOTE_NONE)\n",
    "    return\n",
    "\n",
    "#-! Get links for names ----------------------------#\n",
    "def get_links(names):\n",
    "    names['petpage'] = 'http://neopets.com/~' + names.Neopet\n",
    "    names['pound']   = 'http://neopets.com/pound/adopt.phtml?search=' + names.Neopet\n",
    "    names['img'] = 'http://pets.neopets.com/cpn/' + names.Neopet + '/1/1.png'\n",
    "    return names\n",
    "\n",
    "#-! HTML wrapper functions --------------------------#\n",
    "def div_wrap(to_wrap,clss='pet'):\n",
    "    tagopen = '<div class=\"' + clss + '\">'\n",
    "    tagclosed = '</div>'\n",
    "    return tagopen + to_wrap + tagclosed\n",
    "\n",
    "def a_wrap(to_wrap,link_url):\n",
    "    tagopen0 = '<a href=\"'\n",
    "    tagopen1 = '\">'\n",
    "    tagclosed = '</a>'\n",
    "    return tagopen0 + link_url + tagopen1 + to_wrap + tagclosed\n",
    "\n",
    "def img_wrap(img_urls):\n",
    "    tagopen = '<img src=\"'\n",
    "    tagclosed = '\" />'\n",
    "    return tagopen + img_urls + tagclosed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1196f99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading and ready to use!\n"
     ]
    }
   ],
   "source": [
    "# A thing that lets you \"build\" a name by defining the 'bits' the name is made out of\n",
    "# 'prefix' bit will sample from prefix data\n",
    "# 'suffix' bit will sample from suffix data\n",
    "# any other input string will be used for all names\n",
    "#     (e.g., 'ay' is first 'bit' --> all names will start with 'Ay'\n",
    "\n",
    "class nameBuilder:\n",
    "    \n",
    "    # ----> Set up \n",
    "    def __init__(self,N=300):\n",
    "        \n",
    "        self.constructor = pd.DataFrame(columns=['bit','min','max'])\n",
    "        \n",
    "        # Set up dataframe variables\n",
    "        self.N_names = N\n",
    "        self.segments = pd.DataFrame(index=range(0,N))\n",
    "        self.names = False   #created in once .construct() is called\n",
    "        \n",
    "        self.stats = {'time':'','format':'','name_data':''}\n",
    "\n",
    "    # ----> adds prefix 'bit' to constructor\n",
    "    def add_prefix(self,L=False,Lmin=3,Lmax=14):\n",
    "        \n",
    "        if L != False:\n",
    "            Lmin = L\n",
    "            Lmax = L\n",
    "        \n",
    "        if Lmin < 3:\n",
    "            error('Prefixes must be at least 3 letters long!')\n",
    "            return\n",
    "        \n",
    "        self.constructor = self.constructor.append({\n",
    "            'bit': 'prefix',\n",
    "            'min': Lmin,\n",
    "            'max': Lmax \n",
    "            },ignore_index=True)\n",
    "        \n",
    "    # ----> adds suffix 'bit' to constructor\n",
    "    def add_suffix(self, L = False, Lmin=1, Lmax=8):\n",
    "        \n",
    "        if L != False:\n",
    "            Lmin = L\n",
    "            Lmax = L\n",
    "\n",
    "        self.constructor = self.constructor.append({\n",
    "            'bit': 'suffix',\n",
    "            'min': Lmin,\n",
    "            'max': Lmax\n",
    "            }, ignore_index=True)\n",
    "    \n",
    "    # ----> adds user-defined string 'bit'\n",
    "    def add_bit(self,bit):\n",
    "        self.constructor = self.constructor.append({\n",
    "            'bit': bit,\n",
    "            'min': len(bit),\n",
    "            'max': len(bit) \n",
    "            }, ignore_index=True)\n",
    "    \n",
    "    # ----> Constructs name from constructor matrix\n",
    "    def construct(self, pres=pres, sufs=sufs):\n",
    "        \n",
    "        # ---> iterate through name 'bits'\n",
    "        name_format = '|'\n",
    "        for i in self.constructor.index:\n",
    "            \n",
    "            bit = self.constructor['bit'][i]\n",
    "            Lmin = self.constructor['min'][i]\n",
    "            Lmax = self.constructor['max'][i]\n",
    "            \n",
    "            seggi = bit + '_' + str(i)\n",
    "            name_format += bit + '|'\n",
    "\n",
    "            # ---> Choose data to sample\n",
    "            if bit == 'prefix':\n",
    "                samply = pres[pres.L <= Lmax]\n",
    "                samply = samply.rename(columns={'prefix': 'bit'})\n",
    "                \n",
    "            elif bit == 'suffix':\n",
    "                samply = sufs[sufs.L <= Lmax]\n",
    "                samply = samply.rename(columns={'suffix': 'bit'})\n",
    "            \n",
    "            else:\n",
    "                samply = []\n",
    "                       \n",
    "            # ---> Sample from chosen data  \n",
    "            if bit in ['prefix','suffix']:\n",
    "                \n",
    "                # ---> reduce # of generated names if sampling data is too small\n",
    "                if len(samply) < self.N_names:\n",
    "                    \n",
    "                    self.segments = self.segments.drop(\\\n",
    "                                        index=range(len(samply),self.N_names))\n",
    "                    self.N_names = len(samply)\n",
    "                    \n",
    "                self.segments[seggi] = samply.bit.sample(n = self.N_names).tolist() \n",
    "            \n",
    "            # ---> or copy bit for entire column\n",
    "            else:\n",
    "                self.segments[seggi] = bit\n",
    "                \n",
    "        \n",
    "        self.stats['format'] = name_format.strip() # updates word stats    \n",
    "        \n",
    "        # ---> turn name segments into names\n",
    "        self.names = pd.DataFrame(index = self.segments.index,\n",
    "                                  columns=['L','Neopet'])\n",
    "        self.names.Neopet = ''\n",
    "        \n",
    "        for i in self.segments.columns:\n",
    "            self.names.Neopet +=  self.segments[i]\n",
    "            \n",
    "        \n",
    "        # ---> Get name lengths, sort, and clean up\n",
    "        self.names.L = self.names.Neopet.str.len()\n",
    "        self.names = self.names.drop_duplicates()\\\n",
    "                         .sort_values(by=['L','Neopet'])\\\n",
    "                         .reset_index(drop=True)\n",
    "        \n",
    "        # ---> Capitalize the names\n",
    "        self.names.Neopet = self.names.Neopet.str.capitalize()\n",
    "        \n",
    "        # ---> Apply webpage function\n",
    "        self.to_webpage()\n",
    "\n",
    "    # ---> updates name statistics\n",
    "    def update_stats(self):\n",
    "        stats = {}\n",
    "        for i in self.names.L.unique():\n",
    "            ind = (str(i) + ' Letters')\n",
    "            n = len(self.names[self.names.L == i])\n",
    "            stats.update({ ind : n })\n",
    "        stats.update({' ':'---',\n",
    "                      'All Names':len(self.names)\n",
    "                     })\n",
    "        \n",
    "        \n",
    "        stats = pd.DataFrame.from_dict(stats,orient='index')\n",
    "        stats.columns = [str('NUM')]\n",
    "        \n",
    "        self.stats['name_data'] = stats\n",
    "        self.stats['time'] = dt.datetime.now().time().strftime(\"%I:%M:%S %p\")\n",
    "        \n",
    "        \n",
    "        self.show_stats()\n",
    "        \n",
    "    def show_stats(self):\n",
    "        \n",
    "        print('Constructor\\n'+'------------------')\n",
    "        print(self.constructor)\n",
    "        \n",
    "        print('------------------')\n",
    "        print('\\n' + 'Name Lengths' + \n",
    "              '\\n' + '--------------')\n",
    "        print(self.stats['name_data'])\n",
    "        print('--------------')\n",
    "        print('Last Update @ ' + self.stats['time'])\n",
    "        \n",
    "    def to_webpage(self,link_to='petpage'):\n",
    "        make_page(self.names,link_to)\n",
    "        self.update_stats()\n",
    "        \n",
    "#########################################################\n",
    "print('Done loading and ready to use!')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37afc212",
   "metadata": {},
   "source": [
    "## Name Builder\n",
    "\n",
    "This is where the magic happens!\n",
    "\n",
    "### How to build a name\n",
    "\n",
    "The nameBuilder works by adding 'bits' of words together.\n",
    "* **Prefix** 'bits' sample from the prefix data\n",
    "* **Suffix** 'bits' sample from the suffix data\n",
    "* **string** 'bits' given by the user\n",
    "\n",
    "#### Example nameBuilder: pre_bob_suf\n",
    "\n",
    "This example nameBuilder below makes names with:\n",
    "* a random prefix 3 letters or less\n",
    "* the user-defined string 'bob'\n",
    "* a random suffix with 4 letters or less\n",
    "\n",
    "Names using this `nameBuilder` will look kind of like 'Prebobsuff', 'Xxxbobxxxx', 'Abcbobdefg', etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a17693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nameBuilder\n",
    "pre_bob_suf = nameBuilder()\n",
    "\n",
    "# add in pieces\n",
    "pre_bob_suf.add_prefix(Lmax=3)\n",
    "pre_bob_suf.add_bit('bob')\n",
    "pre_bob_suf.add_suffix(Lmax=4)\n",
    "\n",
    "# now your nameBuilder is ready to be used!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3880da8",
   "metadata": {},
   "source": [
    "#### Make the names\n",
    "Once the nameBuilder is created, to get a list of names in that format, run the builder's `myBuilder.construct()` function. For this example, it looks like this:\n",
    "\n",
    "```pre_bob_suf.construct()```\n",
    "\n",
    "It will randomly choose prefixes & suffixes and update the webpage, and will also show you some stats:\n",
    "\n",
    "* the 'constructor' matrix\n",
    "* the number of names generated of each length\n",
    "* the number of names overall\n",
    "* the last time the constructor was run\n",
    "\n",
    "**You only need to construct the nameBuilder once!** In order to get a new set of names in that format, simply run the `.construct()` function again; it will choose a *new* set of prefixes & suffixes and update the webpage.\n",
    "\n",
    "The webpage is at `HTML/webpage.html`. The `HTML` directory is located in the same folder as this jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94c4e065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructor\n",
      "------------------\n",
      "      bit min max\n",
      "0  prefix   3   3\n",
      "1     bob   3   3\n",
      "2  suffix   1   4\n",
      "------------------\n",
      "\n",
      "Name Lengths\n",
      "--------------\n",
      "            NUM\n",
      "8 Letters     2\n",
      "9 Letters    11\n",
      "10 Letters  287\n",
      "            ---\n",
      "All Names   300\n",
      "--------------\n",
      "Last Update @ 01:40:32 PM\n"
     ]
    }
   ],
   "source": [
    "# use nameBuilder\n",
    "pre_bob_suf.construct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473ad4ca",
   "metadata": {},
   "source": [
    "### nameBuilder Options\n",
    "\n",
    "#### Bit Lengths\n",
    "Limit prefix/suffix bit to a specific length:\n",
    "```myBuilder.add_prefix(L = 3)```\n",
    "\n",
    "Allow a range of lengths:\n",
    "```myBuilder.add_suffix( Lmin=2, Lmax=5 )```\n",
    "\n",
    "\n",
    "\n",
    "#### Use Underscores\n",
    "Python alphabetizes underscores ('\\_') at the *top* of the alphabet, unlike Neopets, which alphebatizes them at the bottom.\n",
    "\n",
    "To get around this, I use tildes ('~'), and the code is set up to convert tildes into underscores right before writing files.\n",
    "\n",
    "Use underscores in user-defined 'bits:\n",
    "```myBuilder.add_bit('~x~')```\n",
    "\n",
    "Sample from stuck prefixes w/ underscores:\n",
    "```myBuilder.construct( pres = pres_ )```\n",
    "\n",
    "\n",
    "### Other constructors to try\n",
    "User-defined prefix, random suffix\n",
    "```\n",
    "bob_suff = nameBuilder()\n",
    "bob_suff.add_bit('bob')\n",
    "bob_suff.add_suffix()\n",
    "```\n",
    "User-defined suffix, random prefix\n",
    "```\n",
    "pre_bob = nameBuilder()\n",
    "pre_bob.add_prefix()\n",
    "pre_bob.add_bit('bob')\n",
    "```\n",
    "Random prefix+suffix\n",
    "```\n",
    "pre_suf = nameBuilder()\n",
    "pre_suf.add_prefix()\n",
    "pre_suf.add_suffix()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeb3582",
   "metadata": {},
   "source": [
    "# Stop Here\n",
    "\n",
    "The code below this is older and no longer used, but I keep it for my own reference (and yours!) It's helpful to learn from, and maybe you can work it into your own functions, but you don't need to run any of it for the name builder to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a2f5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############### Name Generator Fuctions Block ##############\n",
    "### I don't use these anymore, but you may want to\n",
    "### not writing documentation, srry fam\n",
    "\n",
    "#-! Names from user-specified string -----------------------------------#\n",
    "def namesByString( vcn_, pre_suf, link_to = 'petpage', max_L=10, N=300,\\\n",
    "                   suffix = sufs, prefix = pres, alphabet = abcs):\n",
    "\n",
    "    L_left = max_L - len(vcn_)\n",
    "    names = pd.DataFrame(columns=['prefix','suffix','Neopet'])\n",
    "\n",
    "\n",
    "    if pre_suf == 'suffix' and L_left >= 3:\n",
    "\n",
    "        names['prefix'] = prefix[prefix.L <= L_left].prefix.sample(n=N,replace=True).reset_index(drop=True)\n",
    "\n",
    "        names['suffix'] = vcn_\n",
    "\n",
    "\n",
    "    elif pre_suf == 'prefix' and L_left >=1:\n",
    "        names['suffix'] = suffix[suffix.L <= L_left].suffix.sample(n=N,replace=True).reset_index(drop=True)\n",
    "        names['prefix'] = vcn_\n",
    "\n",
    "    else:\n",
    "        return 'Given string is too long for max_L. Increase max_L or decrease input string length.'\n",
    "\n",
    "    names['Neopet'] = names.prefix.str.capitalize() + names.suffix.str.lower()\n",
    "\n",
    "    names = names.drop_duplicates().sort_values(by='Neopet').reset_index(drop=True)\n",
    "\n",
    "    webpage = make_page(names,linky=link_to)\n",
    "\n",
    "    update = 'Names generated :' + str(len(names)) + '\\n' + \\\n",
    "             pre_suf.capitalize() + ':      ' + vcn_ + '\\n' + \\\n",
    "             'Shortest Name: ' + str(names.Neopet.str.len().min()) + '\\n' + \\\n",
    "             'Longest Name:  ' + str(names.Neopet.str.len().max()) + '\\n' + \\\n",
    "             'Timestamp:     ' + dt.datetime.now().time().strftime(\"%I:%M:%S %p\")\n",
    "    \n",
    "    print(update)\n",
    "    print(webpage)\n",
    "    return \n",
    "\n",
    "#-! Names by Length -----------------------------------------------------#\n",
    "def namesByL(L, N=300, link_to='petpage', \\\n",
    "             pre = pres, suffix = sufs, alphabet = abcs):\n",
    "\n",
    "    names = pre[pre.L <= L].sample(n=N).reset_index(drop=True)\n",
    "    names['Ls'] = L - names.L\n",
    "    names['suffix'] = L - names.L\n",
    "\n",
    "    for i in range(names.Ls.min(),names.Ls.max()+1):\n",
    "        if i >=3:\n",
    "            suf_samp = suffix[suffix.L == i].reset_index(drop=True)\n",
    "            suf_samp = suf_samp.sample(n=len(names)).reset_index(drop=True)\n",
    "            suf_samp = suf_samp.suffix.tolist()\n",
    "\n",
    "            names.suffix = names.suffix.mask(names.Ls==i,suf_samp)\n",
    "\n",
    "        elif i == 2:\n",
    "            l1 = alphabet.Letter.sample(n = len(names),replace=True).reset_index()\n",
    "            l2 = alphabet.Letter.sample(n = len(names),replace=True).reset_index()\n",
    "            ls = l1+l2\n",
    "            names.suffix = names.suffix.mask(names.Ls == i, ls.Letter.tolist())\n",
    "\n",
    "        elif i == 1:\n",
    "            l1 = alphabet.Letter.sample(n = len(names),replace=True).tolist()\n",
    "            names.suffix = names.suffix.mask(names.Ls == i, l1)\n",
    "\n",
    "        else:\n",
    "            names.suffix = names.suffix.mask(names.Ls == i,'')\n",
    "\n",
    "\n",
    "    names['Neopet'] = names.prefix.str.capitalize() + names.suffix\n",
    "    names = names.drop_duplicates().sort_values(by='Neopet').reset_index(drop=True)\n",
    "\n",
    "    webpage = make_page(names,linky=link_to)\n",
    "    update = 'Names generated :' + str(len(names)) + '\\n' + \\\n",
    "             'Timestamp:     ' + dt.datetime.now().time().strftime(\"%I:%M:%S %p\")\n",
    "    print(update)\n",
    "    print(webpage)\n",
    "    return\n",
    "\n",
    "#-! Generates page -----------------------------------------------------#\n",
    "######\n",
    "# def make_page(names,linky='petpage'):\n",
    "    \n",
    "#     names['Neopet'] = names.Neopet.str.replace('~','_')\n",
    "\n",
    "            \n",
    "#     css_tag = '<link rel=\"stylesheet\" type=\"text/css\" '+ \\\n",
    "#               'href=\"/style.css\">'\n",
    "\n",
    "#     html0 = '<div class=\"pet\"><a href=\"'\n",
    "#     html1 = '\">'\n",
    "#     html2 = '<br><img src=\"http://pets.neopets.com/cpn/'\n",
    "#     html3 = '/1/1.png\"></a></div>'\n",
    "\n",
    "#     page = pd.DataFrame(columns=['Neopet','html0','link','html1','html2','html3','html'])\n",
    "#     page.Neopet = names.Neopet\n",
    "#     page.html0 = html0\n",
    "#     page.url = pet_url\n",
    "#     page.html1 = html1\n",
    "#     page.html2 = html2\n",
    "#     page.html3 = html3\n",
    "#     page.html = page.html0 + page.url    + \\\n",
    "#                 page.Neopet + page.html1 + \\\n",
    "#                 page.Neopet + page.html2 + \\\n",
    "#                 page.Neopet + page.html3\n",
    "\n",
    "#     webpage = pd.Series(([css_tag]+list(page.html.values)))\n",
    "#     webpage.to_csv('',\n",
    "#                           sep=',',header=False,index=False,quoting=csv.QUOTE_NONE)\n",
    "#     return webpage\n",
    "\n",
    "\n",
    "# Name Generators!\n",
    "# A bit outdated\n",
    "\n",
    "# N = 300\n",
    "# L = 6\n",
    "# link = 'pound'\n",
    "\n",
    "# name_bit = 'cuddle'\n",
    "# bit_label = 'prefix'\n",
    "\n",
    "# namesByL(L,N,link_to=link)\n",
    "# #namesByString(name_bit,bit_label,max_L=L,link_to=link)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb13180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9402a82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
